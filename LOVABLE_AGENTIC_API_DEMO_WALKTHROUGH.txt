Lovable Agentic API (POC)
Demo Walkthrough + How It Works (for Lovable UI build)

Audience
- Marc + Lovable builder (you). Technical but “demo-friendly”.

What this application is
- A small FastAPI backend that:
  1) accepts an UPLOADED seed CSV of leads (exported from your campaign builder)
  2) normalizes it into a consistent Lead model
  3) runs a pipeline (enrich → score → tier → generate tasks)
  4) emits live progress events (polling or SSE)
  5) exposes read APIs for the Lovable dashboard (runs, leads, tasks, metrics)
  6) allows a lightweight “admin” workflow to update task status and track completion

Purpose / the demo story
- You can demo an end-to-end agentic “qualification + enrichment + ranking + explainability + task generation” layer:
  - Upload leads → watch progress live → view ranked leads with reasons → view generated outreach tasks → mark tasks done → see metrics update.

Important safety/ethics constraint
- This POC is designed to work from business/public info.
- It should NOT be used for doxxing or private-life/stalking enrichment.


1) Deployment & Access

Hosted URL (Render)
- Base: https://lovable-agentic-api.onrender.com

Authentication
- All endpoints (except SSE auth is handled manually) require:
  Authorization: Bearer <API_TOKEN>

CORS (Lovable-friendly)
- The API enables CORS via env var CORS_ALLOW_ORIGINS.
- Set it on Render to your Lovable app origin(s), e.g.:
  CORS_ALLOW_ORIGINS=https://your-lovable-app.com
- For demo convenience, server defaults to allowing all origins ("*") unless overridden.

Note on intermittent 502s
- Render edge can sometimes show HTML “502 Bad Gateway” during deploys/cold starts.
- If you get 502, retry after ~30–60s. If you get JSON (401/200), the app is reachable.


2) Data model overview

2.1 CampaignRun
A CampaignRun is the unit of work for a single uploaded CSV + pipeline execution.
Key fields:
- id: cr_<uuid>
- name: display name
- status: draft | running | paused | complete | failed
- criteria: freeform campaign criteria (strings)
- progress: rollup counters for planning + execution
- created_at / updated_at

Progress counters (current)
Planning (pipeline):
- seed_rows_total
- leads_created
- leads_enriched_places
- leads_enriched_website
- leads_scored
- tasks_created
- tasks_completed
- errors

Execution (OutreachAttempts):
- attempts_total
- replies
- meetings

Note: Some older campaign runs created before these fields existed may show null for replies/meetings; the server now initializes these when logging attempts, and the UI should treat missing as 0 for safety.

2.2 Lead
A Lead is the normalized object created from each CSV row.
Key pieces:
- seed: raw-ish normalized seed row fields
- business: name, website, employee_count, address{city,state}, optional google fields
- owner: full_name, emails[] (seed email marked status="valid")
- evidence: sources[] (e.g., google_places, website_page)
- score: total/tier/components/reasoning_bullets
- task_ids: list of generated task ids

2.3 Task
A Task represents an intended action to take (planning).
Key fields:
- type: e.g., email_1, call_1
- channel: email | phone
- status: scheduled | todo | done (POC uses scheduled/done primarily)
- due_at_est: ISO datetime string (stored as text)
- instructions: what to do
- template_id: references an outreach template
- completion: { completed_at, outcome_code, outcome_notes }

2.4 OutreachAttempt (execution record)
An OutreachAttempt represents what actually happened (execution), separate from Tasks.
- One lead can have many OutreachAttempts.
- Logging an attempt does NOT modify or replace Tasks.
Fields:
- id: oa_<uuid>
- campaign_run_id
- lead_id
- channel: email | phone | linkedin | other
- template_id: nullable
- executed_at: ISO timestamp
- outcome_code: sent | delivered | replied | positive | negative | meeting_booked | bounced | unsubscribed
- outcome_notes: nullable text

2.5 Event
Events are emitted during the pipeline (and when logging execution attempts).
Used to power:
- live progress indicator
- activity feed
- debugging


3) CSV integration (Upload → Normalization)

3.1 Upload mechanism
- The CSV is uploaded via multipart/form-data:
  POST /v1/campaign-runs/{id}/import/seed-csv
  form field: file=@/path/to/file.csv

3.2 Required CSV columns (exact header text)
The server validates these headers strictly:
- Contact Name
- Email
- Business Name
- Business Description
- Website
- Status
- Last Email Date
- Employees
- City
- State

If any are missing, import fails with HTTP 400.

3.3 Mapping from CSV to Lead
Each row becomes one Lead with:
- seed.contact_name      <- Contact Name
- seed.email             <- Email
- seed.business_name     <- Business Name
- seed.business_description <- Business Description
- seed.website           <- Website
- seed.status            <- Status
- seed.last_email_date   <- Last Email Date (or null)
- seed.employees         <- Employees (int)
- seed.city              <- City
- seed.state             <- State

Owner email handling (important demo point)
- seed email is treated as already validated:
  lead.owner.emails[0].status = "valid"


4) Pipeline stages (what happens when you hit /run)

The pipeline is implemented in lovable_api/main.py as a background thread runner.

4.1 Start run
- POST /v1/campaign-runs/{id}/run
- This starts a daemon thread. The response returns immediately.

Rerun safety (recent fix)
- If status is "running": HTTP 409 (prevents concurrent runs and inflated counters)
- If status is "complete": HTTP 409 unless force=true
- To force a rerun (rarely needed):
  POST /v1/campaign-runs/{id}/run?force=true

4.2 Progress counters (and how to explain them)
At run start, progress counters are reset for that attempt:
- leads_enriched_places = 0
- leads_enriched_website = 0
- leads_scored = 0
- tasks_created = 0
- errors = 0

seed_rows_total and leads_created remain as imported.

Important: This does not delete old events/tasks; for a pristine demo run history, create a new CampaignRun.

4.3 Enrichment: Google Places (optional, but demo-friendly)
Function: _places_lookup
- Runs ONLY if GOOGLE_MAPS_API_KEY is set.
- Emits a run-level progress payload with:
  - places_enabled: true/false
  - places_cache_ttl_days (default 30)
- Does a text search + details fetch, then caches results in SQLite (places_cache) for ~30 days.
  - This reduces rate-limit risk and makes demos stable.
- Adds to Lead.business.google:
  - place_id, maps_url, rating, reviews, types
  - phone, website, formatted_address
  - latlng (optional)
  - hours_local (optional)
- Adds an evidence source of type google_places with a short field summary.

Demo framing:
- “Places enrichment is enabled when we provide a Google Maps API key. We also cache results so the demo stays fast and consistent.”

4.4 Enrichment: Website fetch (POC)
Function: _website_fetch + _strip_html
- Attempts to HTTP GET the seed website URL (homepage), strips HTML to text.
- Adds evidence source of type website_page with a short snippet.

Demo framing:
- “We can pull lightweight website signals without crawling. This is a POC, not a full crawler.”

4.5 Prompt 1: AI business categorization & extraction (BusinessProfile)
Objective
- Convert noisy lead inputs (seed CSV + Google Places + website text) into a structured, explainable BusinessProfile used downstream.

Where it runs in the pipeline
- After enrichment (Places + website fetch), before scoring.

What gets persisted
- Table: business_profiles (1:1 with lead via lead_id unique)
- BusinessProfile fields (stored + attached into lead JSON as lead.business_profile):
  - vertical_category (controlled list + "unknown")
  - services: string[]
  - customer_type: B2B | B2C | mixed | unknown
  - buyer_persona_hint: string|null
  - credibility_signals: string[]
  - confidence: float 0–1
  - evidence_used: string[] (google_places, website_page, seed_description)
  - raw_llm_json (for debugging)

LLM prompt guardrails (important demo point)
- Must only use facts present in evidence inputs.
- If unsure, output "unknown" and reduce confidence.
- Output must be strict JSON.

Failure behavior (demo-safe)
- If the LLM errors or OpenAI isn’t configured, the run continues:
  - BusinessProfile defaults to unknown/low confidence
  - Event emitted: lead.business_profile_error

Events
- lead.business_profile_extracted
- lead.business_profile_error


4.6 Prompt 2: AI scoring with explanations (hybrid, demo-safe)
Objective
- Produce an AI-assisted score + explanations while keeping deterministic rules scoring as stable fallback.

How it works
- We still compute rules_total using deterministic scoring (Location > Size > Industry).
- Then (if OpenAI configured) we ask the LLM for ai_total + reasoning.
- final_total is clamped to stay near rules_total (demo stability).

Lead.score fields (stored in lead JSON)
- rules_total (0–100)
- ai_total (0–100)
- final_total (0–100)  (back-compat: score.total == final_total)
- tier (A/B/C/D derived from final_total)
- ai_used (bool)
- reasoning_bullets (max 4)
- reasoning_citations (references to BusinessProfile/evidence fields used)

Failure behavior
- If AI scoring fails:
  - ai_total = rules_total
  - ai_used = false
  - run continues

Events
- lead.ai_scored
- lead.ai_scored_error


4.7 Prompt 3: AI personalization & MessageDrafts
Objective
- Generate personalized outreach drafts per lead and persist them as first-class objects.

Where it runs
- After scoring.
- Generates for Tier A/B leads (and also supports a fallback top-N path).

What gets persisted
- Table: message_drafts
- Fields: id, campaign_run_id, lead_id, channel, template_id, subject, body, personalization_facts[], safety_checks_passed, created_at

Guardrails
- Must only use facts in BusinessProfile or enrichment evidence.
- If not enough evidence, draft is generic with fewer specifics.
- Draft failure does NOT fail the run.

Events
- lead.message_draft_created
- lead.message_draft_error


4.8 Task generation (and tactic attribution)
Function: _generate_tasks_stub
- For eligible leads, creates tasks like:
  - email_1
  - call_1

Rules
- By default, tasks are created for tier A/B.

Fallback behavior (key demo feature)
- If no A/B tasks are created, the POC creates tasks for top N leads anyway.
- Controlled by env var: TASK_TOP_N (default 25)
- The fallback emits events with payload.reason = "fallback_top_n".

Tactics/experiments attribution (Prompt 4 MVP)
- If there is an active experiment for the campaign:
  - a deterministic subset of eligible leads gets the tactic variant
  - tasks are tagged with tactic_id + experiment_id


5) API surface (what Lovable should call)

All endpoints require Authorization: Bearer <API_TOKEN>

5.0 Health checks
- GET /v1/health (NO AUTH)
  Returns { ok:true, service, time }.
  Use this for Render liveness / uptime probes.

- GET /v1/health/openai (AUTH)
  Returns whether OpenAI is configured.
  - Optional: /v1/health/openai?probe=true to actually call the model (debug).


5.1 Campaign runs
- POST /v1/campaign-runs
  Creates a CampaignRun.

- GET /v1/campaign-runs
  Lists recent runs (Lovable index page).
  Query params: limit, cursor, status
  Returns {items, nextCursor}.

- GET /v1/campaign-runs/{id}
  Returns run status + progress.

- POST /v1/campaign-runs/{id}/import/seed-csv
  Upload seed CSV.

- POST /v1/campaign-runs/{id}/run
  Starts pipeline.
  - 200 when started
  - 409 if already running
  - 409 if complete (unless force=true)

Admin “unstick”
- POST /v1/campaign-runs/{id}/abort
  Sets status=aborted and the runner will exit on its next status check.

5.2 Events (live progress)
Default (recommended for demo): polling
- GET /v1/campaign-runs/{id} every ~2s (status + progress)
- GET /v1/campaign-runs/{id}/events?cursor=... every ~2s
  Returns {events[], nextCursor}

Optional (do not depend on it for demo): SSE
- GET /v1/campaign-runs/{id}/events/stream
  SSE stream for near-real-time UI.
  Notes:
  - SSE + Authorization headers + CORS varies by host; keep this as an enhancement.

Event types you’ll see in practice:
- progress (campaign created/imported/run started/progress reset/run complete)
- campaign.aborted
- lead.places_enriched
- lead.website_enriched
- lead.business_profile_extracted
- lead.business_profile_error
- lead.ai_scored
- lead.ai_scored_error
- lead.message_draft_created
- lead.message_draft_error
- lead.tasks_created
- task.completed
- attempt.logged (created when real-world outreach execution is logged)
- campaign.tactics_generated
- campaign.experiment_started
- campaign.experiment_ended

5.3 Leads
- GET /v1/campaign-runs/{id}/leads
  Query params:
  - tier= A,B,C (comma-separated)
  - sort=score_desc|score_asc
  - limit, cursor

- GET /v1/leads/{leadId}
  Lead detail.
  Includes:
  - business_profile
  - score fields (rules_total/ai_total/final_total/tier/etc.)
  - message_drafts (generated drafts for this lead)

MessageDrafts
- GET /v1/message-drafts?campaign_run_id=...&lead_id=...&channel=email
  Lists persisted drafts.

Escape hatch (backfill drafts after-the-fact)
- POST /v1/campaign-runs/{id}/generate-message-drafts?tier=A,B&limit=25

5.4 Tasks
- GET /v1/tasks
  Query params:
  - campaign_run_id
  - status (comma-separated)
  - due_before
  - limit

- PATCH /v1/tasks/{taskId}
  Update status and/or completion.
  When status becomes "done", the API increments tasks_completed and emits task.completed event.

5.5 OutreachAttempts (execution logging)
Two endpoints exist:
- POST /v1/attempts (recommended)
  - Purpose: dead-simple execution logging for ops/programmatic use.
  - Behavior:
    - inserts an OutreachAttempt (oa_...)
    - emits event: attempt.logged
    - updates CampaignRun.progress rollups:
      attempts_total += 1
      replies += 1 for outcomes: replied|positive|negative|meeting_booked
      meetings += 1 for outcome: meeting_booked
  - Response: 201 Created

- POST /v1/outreach-attempts (back-compat)
  - Same behavior, returns 200.

List attempts:
- GET /v1/outreach-attempts
  Query params:
  - campaign_run_id
  - lead_id
  - limit

OutreachAttempt payload shape (example)
{
  "campaign_run_id": "cr_xxx",
  "lead_id": "ld_xxx",
  "channel": "email",
  "template_id": "E1_MANDATE_SALEONLY",
  "tactic_id": null,
  "experiment_id": null,
  "executed_at": "2026-02-06T15:04:00Z",
  "outcome_code": "sent",
  "outcome_notes": "Initial outreach email sent"
}

5.6 Metrics
- GET /v1/metrics/overview
  Existing planning metrics remain:
  - leads_total
  - tiers {A,B,C,D}
  - tasks_total
  - tasks_done
  - task_completion_rate

  Outcome/execution metrics (client-facing):
  - attempts_total
  - attempts_by_channel {email, phone, linkedin, other}
  - replies_total (outcome_code in replied|positive|negative|meeting_booked)
  - positive_replies_total (outcome_code in positive|meeting_booked)
  - meetings_total (outcome_code=meeting_booked)
  - bounces_total (outcome_code=bounced)
  - unsubscribes_total (outcome_code=unsubscribed)
  - bounce_rate = bounces_total / attempts_total
  - reply_rate = replies_total / attempts_total
  - meeting_rate = meetings_total / attempts_total

  Last 7 days (based on executed_at >= last_7d_cutoff_utc):
  - attempts_last_7d
  - replies_last_7d
  - meetings_last_7d
  - reply_rate_last_7d
  - meeting_rate_last_7d
  - last_7d_cutoff_utc

  Notes:
  - Metrics are computed dynamically from OutreachAttempt rows (no cached rollups needed in this POC).
  - When showing rates, guard against attempts_total=0.
  - Prompt 4 MVP adds basic attribution: attempts_by_tactic (if attempts were logged with tactic_id).

5.7 Prompt 4: Tactics + Experiments (campaign intelligence loop)
- POST /v1/campaign-runs/{id}/tactics/generate
  Generates 3–5 AI-proposed tactics based on outcomes + lead distribution.
  Stores as Tactic(status=proposed).

- GET /v1/tactics?campaign_run_id=...
  List proposed/active tactics.

Human activation (required)
- POST /v1/tactics/{tactic_id}/activate?allocation_pct=10
  Starts an Experiment(status=active) and flips tactic to active.
  (MVP constraint: one active experiment at a time per campaign.)

- GET /v1/experiments?campaign_run_id=...
  List experiments.

- POST /v1/experiments/{experiment_id}/end
  Ends an experiment.

Allocator behavior (important demo point)
- Only ACTIVE experiments apply.
- A deterministic subset of eligible leads gets the tactic variant (so reruns are stable).
- Tasks created under the experiment carry tactic_id + experiment_id.


6) Lovable frontend: recommended screens/components

6.1 “Campaign Runs” page
Goal: list runs and let user create/start a run.
Components:
- Create run form: name + criteria (free text)
- Runs table:
  - name, status, created_at, leads_created, leads_scored, tasks_created
  - button: View

6.2 “Run Detail” page
Goal: the main demo page.
Layout idea:
A) Header
- run name, run id, status badge
- progress summary: scored/enriched/tasks/errors

B) Live progress
- Poll /v1/campaign-runs/{id} every 2s OR subscribe to SSE.
- Optional “Activity feed” from /events.

C) Lead leaderboard
- Table from /campaign-runs/{id}/leads?sort=score_desc
Columns:
- business_name, city/state, employees
- owner_email
- score_total, tier
- vertical_category, profile_confidence
- top_reasons (3 bullets)
- next_task (if any)
Actions:
- open lead detail

D) Tasks preview
- show tasks for this campaign: /tasks?campaign_run_id=<id>
- filter by status

6.3 “Lead Detail” page
Goal: explainability and enrichment evidence.
Show these blocks:
- Seed fields (what we imported)
- Evidence sources (Google Places + website snippet)
- BusinessProfile (Prompt 1)
  - vertical_category, services, customer_type, credibility_signals, confidence
- Score (Prompt 2)
  - rules_total, ai_total, final_total, tier, ai_used
  - reasoning_bullets + reasoning_citations
- MessageDrafts (Prompt 3)
  - show latest email draft body + personalization_facts
- Tasks for this lead

6.4 “Tasks Admin” page
Goal: assign and track tasks (no rep assignment required yet).
- List tasks (campaign_run filter + status filter)
- Bulk actions:
  - mark done
  - update outcome_notes

Implementation detail:
- PATCH /v1/tasks/{taskId}
  body example:
  {
    "status": "done",
    "completion": {
      "completed_at": "2026-02-05T15:02:00Z",
      "outcome_code": "sent",
      "outcome_notes": "Sent intro email"
    }
  }

6.5 Metrics page
Goal: lightweight reporting + “this is what the client pays for”.
- call /v1/metrics/overview?campaign_run_id=<id>

Recommended Lovable UI widgets (mapping)
A) KPI row (big numbers)
- Attempts sent
  - value: attempts_total
  - subtitle: attempts_by_channel.email / phone / linkedin / other
- Replies
  - value: replies_total
  - secondary: reply_rate (format as %)
- Positive replies
  - value: positive_replies_total
- Meetings booked
  - value: meetings_total
  - secondary: meeting_rate (format as %)

B) Deliverability / list health
- Bounces
  - value: bounces_total
  - secondary: bounce_rate (format as %)
- Unsubscribes
  - value: unsubscribes_total

C) Last 7 days (velocity)
- Attempts (7d): attempts_last_7d
- Replies (7d): replies_last_7d
  - secondary: reply_rate_last_7d
- Meetings (7d): meetings_last_7d
  - secondary: meeting_rate_last_7d
- “7d window begins”: last_7d_cutoff_utc (small caption)

D) Existing planning metrics (still useful, but not the headline)
- Leads total: leads_total
- Tier distribution: tiers (A/B/C/D)
- Tasks: tasks_done / tasks_total
- Task completion: task_completion_rate

Notes for Lovable formatting
- Always guard division by zero when showing rates; the API already returns 0.0 for rates when denom=0.
- Consider showing both "All-time" and "Last 7d" side-by-side for the client-facing dashboard.


7) Demo script (what to show in order)

A) Setup
- Explain: “We ingest a validated-email lead export (CSV).”

B) Create CampaignRun
- In Lovable: enter name + criteria.
- Call POST /v1/campaign-runs.

C) Upload CSV
- Lovable file upload -> POST /import/seed-csv.
- Confirm imported count.

D) Start pipeline
- Click Start -> POST /run.
- Show live updating counters.
- Show events feed (optional).

E) Show ranked leads
- Show top leads with “why” bullets.

F) Show tasks created
- Show tasks list.
- Mention fallback: even if A/B is empty, we still create tasks for top N so the workflow proceeds.

G) Admin marks tasks done
- Toggle some tasks to done.
- Show task-based metrics update and task.completed events.

H) Ops logs real-world execution (this is the paid-service proof)
- Use POST /v1/attempts to log an email sent, a reply, a bounce, and a meeting booked.
- Show:
  - attempt.logged events
  - /v1/outreach-attempts list
  - /v1/metrics/overview outcome metrics (attempts_total, reply_rate, meetings_total, bounce_rate, last_7d)


8) Known limitations / POC notes (be explicit in demo)

- Scoring is a deterministic stub (location/size/industry). It’s intentionally simple and explainable.
- Google Places enrichment requires GOOGLE_MAPS_API_KEY. Without it, places enrichment is skipped.
  - The run emits a progress payload field places_enabled so the UI can show Enabled/Disabled explicitly.
  - Places results are cached in SQLite (TTL ~30 days) to reduce jitter and rate-limit issues during demos.
- Website enrichment is a single-page fetch; not a crawler.
- No true LLM extraction in the POC.
- SQLite is used for persistence (DB_PATH env var; Render uses a disk path like /var/data/poc.db).
- Render may occasionally 502 during deploy/cold starts; retry.
- For clean progress reporting, use a fresh CampaignRun per demo.


9) Appendix: Quick cURL examples

Set env vars in your shell (example):
- export BASE=https://lovable-agentic-api.onrender.com
- export TOKEN=... (API token)

Create run:
curl -sS -X POST -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" \
  -d '{"name":"Demo","criteria":{"locations_text":"FL","size_text":"10-200 employees"}}' \
  "$BASE/v1/campaign-runs"

Import CSV:
curl -sS -X POST -H "Authorization: Bearer $TOKEN" \
  -F "file=@/home/curl/.openclaw/workspace/new-claw-fixed.csv" \
  "$BASE/v1/campaign-runs/<RUN_ID>/import/seed-csv"

Run:
curl -sS -X POST -H "Authorization: Bearer $TOKEN" "$BASE/v1/campaign-runs/<RUN_ID>/run"

List leads:
curl -sS -H "Authorization: Bearer $TOKEN" "$BASE/v1/campaign-runs/<RUN_ID>/leads?limit=10&sort=score_desc"

List tasks:
curl -sS -H "Authorization: Bearer $TOKEN" "$BASE/v1/tasks?campaign_run_id=<RUN_ID>&limit=10"

Mark task done:
curl -sS -X PATCH -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" \
  -d '{"status":"done","completion":{"completed_at":"2026-02-05T15:00:00Z","outcome_code":"sent","outcome_notes":"Sent"}}' \
  "$BASE/v1/tasks/<TASK_ID>"

Log execution attempt (201):
curl -sS -X POST -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" \
  -d '{"campaign_run_id":"<RUN_ID>","lead_id":"<LEAD_ID>","channel":"email","template_id":"E1_MANDATE_SALEONLY","executed_at":"2026-02-06T15:04:00Z","outcome_code":"sent","outcome_notes":"Initial outreach email sent"}' \
  "$BASE/v1/attempts"

List execution attempts:
curl -sS -H "Authorization: Bearer $TOKEN" "$BASE/v1/outreach-attempts?campaign_run_id=<RUN_ID>&lead_id=<LEAD_ID>&limit=5"

Metrics:
curl -sS -H "Authorization: Bearer $TOKEN" "$BASE/v1/metrics/overview?campaign_run_id=<RUN_ID>"
